{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这部分实现了CBOW词嵌入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2186ad609d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': 0, 'science': 1}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_ix = {'data': 0, 'science': 1}\n",
    "word_to_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(2, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeds = nn.Embedding(2, 5)\n",
    "embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lookup_tensor = torch.tensor([word_to_ix['data']], dtype=torch.long)\n",
    "lookup_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0461,  0.4024, -1.0115,  0.2167, -0.6123]],\n",
      "       grad_fn=<EmbeddingBackward>)\n"
     ]
    }
   ],
   "source": [
    "hello_embed = embeds(lookup_tensor)\n",
    "print(hello_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTEXT_SIZE = 2\n",
    "EMBEDDING_DIM = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentence = \"\"\"Alternate data extraction is when actual data is not available to the user, but the user can use the Internet to fetch data that is publicly available, and search for relevant information. For example, if I want to buy a laptop, I want to compare the price of the laptop on various online portals. I have one system scrape the price information from various websites and provide a summary of the prices to me. This process is called alternate data collection using web scraping, text processing and natural language processing.\"\"\".split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['Alternate', 'data'], 'extraction'), (['data', 'extraction'], 'is'), (['extraction', 'is'], 'when')]\n"
     ]
    }
   ],
   "source": [
    "trigrams = [([test_sentence[i], test_sentence[i + 1]], test_sentence[i + 2])\n",
    "            for i in range(len(test_sentence) - 2)\n",
    "           ]\n",
    "print(trigrams[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set(test_sentence)\n",
    "word_to_ix = {word: i for i, word in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Alternate',\n",
       " 'For',\n",
       " 'I',\n",
       " 'Internet',\n",
       " 'This',\n",
       " 'a',\n",
       " 'actual',\n",
       " 'alternate',\n",
       " 'and',\n",
       " 'available',\n",
       " 'available,',\n",
       " 'but',\n",
       " 'buy',\n",
       " 'called',\n",
       " 'can',\n",
       " 'collection',\n",
       " 'compare',\n",
       " 'data',\n",
       " 'example,',\n",
       " 'extraction',\n",
       " 'fetch',\n",
       " 'for',\n",
       " 'from',\n",
       " 'have',\n",
       " 'if',\n",
       " 'information',\n",
       " 'information.',\n",
       " 'is',\n",
       " 'language',\n",
       " 'laptop',\n",
       " 'laptop,',\n",
       " 'me.',\n",
       " 'natural',\n",
       " 'not',\n",
       " 'of',\n",
       " 'on',\n",
       " 'one',\n",
       " 'online',\n",
       " 'portals.',\n",
       " 'price',\n",
       " 'prices',\n",
       " 'process',\n",
       " 'processing',\n",
       " 'processing.',\n",
       " 'provide',\n",
       " 'publicly',\n",
       " 'relevant',\n",
       " 'scrape',\n",
       " 'scraping,',\n",
       " 'search',\n",
       " 'summary',\n",
       " 'system',\n",
       " 'text',\n",
       " 'that',\n",
       " 'the',\n",
       " 'to',\n",
       " 'use',\n",
       " 'user',\n",
       " 'user,',\n",
       " 'using',\n",
       " 'various',\n",
       " 'want',\n",
       " 'web',\n",
       " 'websites',\n",
       " 'when'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'have': 0,\n",
       " 'actual': 1,\n",
       " 'portals.': 2,\n",
       " 'information': 3,\n",
       " 'called': 4,\n",
       " 'various': 5,\n",
       " 'fetch': 6,\n",
       " 'available,': 7,\n",
       " 'price': 8,\n",
       " 'to': 9,\n",
       " 'but': 10,\n",
       " 'if': 11,\n",
       " 'one': 12,\n",
       " 'system': 13,\n",
       " 'when': 14,\n",
       " 'information.': 15,\n",
       " 'the': 16,\n",
       " 'search': 17,\n",
       " 'data': 18,\n",
       " 'that': 19,\n",
       " 'for': 20,\n",
       " 'buy': 21,\n",
       " 'summary': 22,\n",
       " 'collection': 23,\n",
       " 'user,': 24,\n",
       " 'provide': 25,\n",
       " 'and': 26,\n",
       " 'Alternate': 27,\n",
       " 'I': 28,\n",
       " 'prices': 29,\n",
       " 'is': 30,\n",
       " 'process': 31,\n",
       " 'For': 32,\n",
       " 'natural': 33,\n",
       " 'laptop': 34,\n",
       " 'not': 35,\n",
       " 'using': 36,\n",
       " 'user': 37,\n",
       " 'web': 38,\n",
       " 'publicly': 39,\n",
       " 'a': 40,\n",
       " 'compare': 41,\n",
       " 'laptop,': 42,\n",
       " 'websites': 43,\n",
       " 'processing.': 44,\n",
       " 'scraping,': 45,\n",
       " 'example,': 46,\n",
       " 'available': 47,\n",
       " 'Internet': 48,\n",
       " 'scrape': 49,\n",
       " 'alternate': 50,\n",
       " 'use': 51,\n",
       " 'from': 52,\n",
       " 'me.': 53,\n",
       " 'can': 54,\n",
       " 'relevant': 55,\n",
       " 'online': 56,\n",
       " 'want': 57,\n",
       " 'This': 58,\n",
       " 'text': 59,\n",
       " 'on': 60,\n",
       " 'extraction': 61,\n",
       " 'of': 62,\n",
       " 'language': 63,\n",
       " 'processing': 64}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NGramLanguageModeler(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, context_size):\n",
    "        super(NGramLanguageModeler, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.linear1 = nn.Linear(context_size * embedding_dim, 128)\n",
    "        self.linear2 = nn.Linear(128, vocab_size)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        embeds = self.embeddings(inputs).view((1, -1))\n",
    "        out = F.relu(self.linear1(embeds))\n",
    "        out = self.linear2(out)\n",
    "        log_probs = F.log_softmax(out, dim=1)\n",
    "        return log_probs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NGramLanguageModeler(\n",
       "  (embeddings): Embedding(65, 10)\n",
       "  (linear1): Linear(in_features=20, out_features=128, bias=True)\n",
       "  (linear2): Linear(in_features=128, out_features=65, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses = []\n",
    "loss_function = nn.NLLLoss()\n",
    "model = NGramLanguageModeler(len(vocab), EMBEDDING_DIM, CONTEXT_SIZE)\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-3)\n",
    "losses\n",
    "loss_function\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGD (\n",
       "Parameter Group 0\n",
       "    dampening: 0\n",
       "    lr: 0.001\n",
       "    momentum: 0\n",
       "    nesterov: False\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[372.0579733848572]\n",
      "[372.0579733848572, 369.7833273410797]\n",
      "[372.0579733848572, 369.7833273410797, 367.53419947624207]\n",
      "[372.0579733848572, 369.7833273410797, 367.53419947624207, 365.3097529411316]\n",
      "[372.0579733848572, 369.7833273410797, 367.53419947624207, 365.3097529411316, 363.1089813709259]\n",
      "[372.0579733848572, 369.7833273410797, 367.53419947624207, 365.3097529411316, 363.1089813709259, 360.93003273010254]\n",
      "[372.0579733848572, 369.7833273410797, 367.53419947624207, 365.3097529411316, 363.1089813709259, 360.93003273010254, 358.77337193489075]\n",
      "[372.0579733848572, 369.7833273410797, 367.53419947624207, 365.3097529411316, 363.1089813709259, 360.93003273010254, 358.77337193489075, 356.63872599601746]\n",
      "[372.0579733848572, 369.7833273410797, 367.53419947624207, 365.3097529411316, 363.1089813709259, 360.93003273010254, 358.77337193489075, 356.63872599601746, 354.52529549598694]\n",
      "[372.0579733848572, 369.7833273410797, 367.53419947624207, 365.3097529411316, 363.1089813709259, 360.93003273010254, 358.77337193489075, 356.63872599601746, 354.52529549598694, 352.4320442676544]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    total_loss = 0\n",
    "    for context, target in trigrams:\n",
    "        context_idxs = torch.tensor([word_to_ix[w] for w in context], dtype=torch.long)\n",
    "        \n",
    "        model.zero_grad()\n",
    "        log_probs = model(context_idxs)\n",
    "        loss = loss_function(log_probs, torch.tensor([word_to_ix[target]], dtype=torch.long))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    losses.append(total_loss)\n",
    "\n",
    "    print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([33, 63])\n"
     ]
    }
   ],
   "source": [
    "print(context_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NGramLanguageModeler(\n",
       "  (embeddings): Embedding(65, 10)\n",
       "  (linear1): Linear(in_features=20, out_features=128, bias=True)\n",
       "  (linear2): Linear(in_features=128, out_features=65, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-4.1876, -4.0142, -4.0249, -4.3971, -4.0504, -4.0775, -3.7069, -4.4298,\n",
       "         -4.1983, -3.7377, -4.7659, -4.3369, -4.6147, -4.4581, -3.7786, -4.2146,\n",
       "         -3.7002, -4.5736, -3.5534, -4.6636, -4.0253, -4.3277, -4.3748, -4.4652,\n",
       "         -4.3315, -4.7749, -4.0555, -3.8370, -4.0306, -3.8088, -4.2948, -4.3594,\n",
       "         -4.0110, -4.6627, -3.9585, -4.0355, -4.0777, -4.3592, -4.4203, -4.4619,\n",
       "         -3.7170, -4.4907, -4.4841, -4.5382, -3.5864, -4.1611, -4.5496, -4.1264,\n",
       "         -4.4953, -4.6569, -4.6671, -3.6328, -3.9784, -4.4483, -4.4728, -4.5906,\n",
       "         -4.1571, -4.1133, -4.2543, -4.0717, -4.2258, -4.5225, -4.3673, -4.4489,\n",
       "         -3.7132]], grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(context_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-4.1866, -4.0129, -4.0243, -4.3958, -4.0501, -4.0764, -3.7059, -4.4281,\n",
      "         -4.1977, -3.7362, -4.7646, -4.3360, -4.6129, -4.4574, -3.7782, -4.2132,\n",
      "         -3.6987, -4.5742, -3.5513, -4.6626, -4.0238, -4.3262, -4.3736, -4.4656,\n",
      "         -4.3309, -4.7744, -4.0549, -3.8355, -4.0293, -3.8078, -4.2936, -4.3574,\n",
      "         -4.0102, -4.6616, -3.9576, -4.0342, -4.0765, -4.3585, -4.4183, -4.4595,\n",
      "         -3.7161, -4.4891, -4.4834, -4.5377, -3.6260, -4.1592, -4.5492, -4.1247,\n",
      "         -4.4944, -4.6571, -4.6659, -3.6311, -3.9775, -4.4471, -4.4724, -4.5890,\n",
      "         -4.1556, -4.1118, -4.2545, -4.0700, -4.2247, -4.5222, -4.3666, -4.4482,\n",
      "         -3.7120]], grad_fn=<LogSoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(log_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([44])\n"
     ]
    }
   ],
   "source": [
    "print(torch.tensor([word_to_ix[target]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NLLLoss()"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NLLLoss()"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__call__',\n",
       " '__class__',\n",
       " '__constants__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_apply',\n",
       " '_backward_hooks',\n",
       " '_buffers',\n",
       " '_forward_hooks',\n",
       " '_forward_pre_hooks',\n",
       " '_get_name',\n",
       " '_load_from_state_dict',\n",
       " '_load_state_dict_pre_hooks',\n",
       " '_modules',\n",
       " '_named_members',\n",
       " '_parameters',\n",
       " '_register_load_state_dict_pre_hook',\n",
       " '_register_state_dict_hook',\n",
       " '_replicate_for_data_parallel',\n",
       " '_save_to_state_dict',\n",
       " '_slow_forward',\n",
       " '_state_dict_hooks',\n",
       " '_version',\n",
       " 'add_module',\n",
       " 'apply',\n",
       " 'bfloat16',\n",
       " 'buffers',\n",
       " 'children',\n",
       " 'cpu',\n",
       " 'cuda',\n",
       " 'double',\n",
       " 'dump_patches',\n",
       " 'eval',\n",
       " 'extra_repr',\n",
       " 'float',\n",
       " 'forward',\n",
       " 'half',\n",
       " 'ignore_index',\n",
       " 'load_state_dict',\n",
       " 'modules',\n",
       " 'named_buffers',\n",
       " 'named_children',\n",
       " 'named_modules',\n",
       " 'named_parameters',\n",
       " 'parameters',\n",
       " 'reduction',\n",
       " 'register_backward_hook',\n",
       " 'register_buffer',\n",
       " 'register_forward_hook',\n",
       " 'register_forward_pre_hook',\n",
       " 'register_parameter',\n",
       " 'requires_grad_',\n",
       " 'share_memory',\n",
       " 'state_dict',\n",
       " 'to',\n",
       " 'train',\n",
       " 'training',\n",
       " 'type',\n",
       " 'weight',\n",
       " 'zero_grad']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(loss_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里实现CBOW词嵌入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Alternate',\n",
       " 'For',\n",
       " 'I',\n",
       " 'Internet',\n",
       " 'This',\n",
       " 'a',\n",
       " 'actual',\n",
       " 'alternate',\n",
       " 'and',\n",
       " 'available',\n",
       " 'available,',\n",
       " 'but',\n",
       " 'buy',\n",
       " 'called',\n",
       " 'can',\n",
       " 'collection',\n",
       " 'compare',\n",
       " 'data',\n",
       " 'example,',\n",
       " 'extraction',\n",
       " 'fetch',\n",
       " 'for',\n",
       " 'from',\n",
       " 'have',\n",
       " 'if',\n",
       " 'information',\n",
       " 'information.',\n",
       " 'is',\n",
       " 'language',\n",
       " 'laptop',\n",
       " 'laptop,',\n",
       " 'me.',\n",
       " 'natural',\n",
       " 'not',\n",
       " 'of',\n",
       " 'on',\n",
       " 'one',\n",
       " 'online',\n",
       " 'portals.',\n",
       " 'price',\n",
       " 'prices',\n",
       " 'process',\n",
       " 'processing',\n",
       " 'processing.',\n",
       " 'provide',\n",
       " 'publicly',\n",
       " 'relevant',\n",
       " 'scrape',\n",
       " 'scraping,',\n",
       " 'search',\n",
       " 'summary',\n",
       " 'system',\n",
       " 'text',\n",
       " 'that',\n",
       " 'the',\n",
       " 'to',\n",
       " 'use',\n",
       " 'user',\n",
       " 'user,',\n",
       " 'using',\n",
       " 'various',\n",
       " 'want',\n",
       " 'web',\n",
       " 'websites',\n",
       " 'when'}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "vocab = set(test_sentence)\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(vocab)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'have': 0,\n",
       " 'actual': 1,\n",
       " 'portals.': 2,\n",
       " 'information': 3,\n",
       " 'called': 4,\n",
       " 'various': 5,\n",
       " 'fetch': 6,\n",
       " 'available,': 7,\n",
       " 'price': 8,\n",
       " 'to': 9,\n",
       " 'but': 10,\n",
       " 'if': 11,\n",
       " 'one': 12,\n",
       " 'system': 13,\n",
       " 'when': 14,\n",
       " 'information.': 15,\n",
       " 'the': 16,\n",
       " 'search': 17,\n",
       " 'data': 18,\n",
       " 'that': 19,\n",
       " 'for': 20,\n",
       " 'buy': 21,\n",
       " 'summary': 22,\n",
       " 'collection': 23,\n",
       " 'user,': 24,\n",
       " 'provide': 25,\n",
       " 'and': 26,\n",
       " 'Alternate': 27,\n",
       " 'I': 28,\n",
       " 'prices': 29,\n",
       " 'is': 30,\n",
       " 'process': 31,\n",
       " 'For': 32,\n",
       " 'natural': 33,\n",
       " 'laptop': 34,\n",
       " 'not': 35,\n",
       " 'using': 36,\n",
       " 'user': 37,\n",
       " 'web': 38,\n",
       " 'publicly': 39,\n",
       " 'a': 40,\n",
       " 'compare': 41,\n",
       " 'laptop,': 42,\n",
       " 'websites': 43,\n",
       " 'processing.': 44,\n",
       " 'scraping,': 45,\n",
       " 'example,': 46,\n",
       " 'available': 47,\n",
       " 'Internet': 48,\n",
       " 'scrape': 49,\n",
       " 'alternate': 50,\n",
       " 'use': 51,\n",
       " 'from': 52,\n",
       " 'me.': 53,\n",
       " 'can': 54,\n",
       " 'relevant': 55,\n",
       " 'online': 56,\n",
       " 'want': 57,\n",
       " 'This': 58,\n",
       " 'text': 59,\n",
       " 'on': 60,\n",
       " 'extraction': 61,\n",
       " 'of': 62,\n",
       " 'language': 63,\n",
       " 'processing': 64}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "word_to_ix = {word: i for i, word in enumerate(vocab)}\n",
    "word_to_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['Alternate', 'data', 'is', 'when'], 'extraction'), (['data', 'extraction', 'when', 'actual'], 'is'), (['extraction', 'is', 'actual', 'data'], 'when'), (['is', 'when', 'data', 'is'], 'actual'), (['when', 'actual', 'is', 'not'], 'data')]\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "# 构建所有的环境及目标词\n",
    "for i in range(2, len(test_sentence) - 2):\n",
    "    context = [test_sentence[i - 2], test_sentence[i - 1], \n",
    "               test_sentence[i + 1], test_sentence[i + 2]\n",
    "              ]\n",
    "    target = test_sentence[i]\n",
    "    data.append((context, target))\n",
    "print(data[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBOW(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, context_size):\n",
    "        super(CBOW, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        # 定义网络的投影层\n",
    "        self.proj = nn.Linear(embedding_dim, 128)\n",
    "        # 网络的输出层\n",
    "        self.output = nn.Linear(128, vocab_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # 获取inputs中词的嵌入\n",
    "        embeds = []\n",
    "        for w in inputs:\n",
    "            embed = self.embeddings(w).view(1, -1)\n",
    "            embeds.append(embed)\n",
    "        # 对嵌入求和：Wx1 + Wx2 + Wx3 + Wx4 = W(x1 + x2 + x3 + x4)\n",
    "        embeds = sum(embeds)\n",
    "        out = F.relu(self.proj(embeds))\n",
    "        log_probs = F.log_softmax(out, dim=1)\n",
    "        return log_probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义损失函数和优化器\n",
    "losses = []\n",
    "loss_function = nn.NLLLoss()\n",
    "model = CBOW(len(vocab), EMBEDDING_DIM, CONTEXT_SIZE)\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208.6863633543253\n",
      "208.38795844838023\n",
      "208.0932647176087\n",
      "207.80281068757176\n",
      "207.51611502841115\n",
      "207.23331578448415\n",
      "206.9541219882667\n",
      "206.67829656228423\n",
      "206.4057732336223\n",
      "206.13634933158755\n",
      "205.86997857689857\n",
      "205.60662449523807\n",
      "205.34641610831022\n",
      "205.0891963802278\n",
      "204.83483144268394\n",
      "204.5834595542401\n",
      "204.33500672876835\n",
      "204.0893378406763\n",
      "203.84638259001076\n",
      "203.6062051448971\n",
      "203.3684559520334\n",
      "203.13323623500764\n",
      "202.90072415024042\n",
      "202.6708982102573\n",
      "202.44377980194986\n",
      "202.2192131653428\n",
      "201.99729256518185\n",
      "201.77779319509864\n",
      "201.56055908463895\n",
      "201.34588747099042\n",
      "201.13416194170713\n",
      "200.92486174590886\n",
      "200.71767022833228\n",
      "200.5127201974392\n",
      "200.3098196387291\n",
      "200.10889574885368\n",
      "199.91011080890894\n",
      "199.7134053464979\n",
      "199.51872726529837\n",
      "199.32613850571215\n",
      "199.13555622659624\n",
      "198.94699480198324\n",
      "198.76053553260863\n",
      "198.57607009075582\n",
      "198.39408857002854\n",
      "198.2140520568937\n",
      "198.03632125258446\n",
      "197.86037406884134\n",
      "197.68625896796584\n",
      "197.51395700499415\n",
      "197.3434186745435\n",
      "197.17473141103983\n",
      "197.00768603384495\n",
      "196.8424386177212\n",
      "196.67919011227787\n",
      "196.51735453493893\n",
      "196.35727592930198\n",
      "196.19874003902078\n",
      "196.0419779997319\n",
      "195.8868905287236\n",
      "195.733422242105\n",
      "195.581657493487\n",
      "195.4315903633833\n",
      "195.2831274792552\n",
      "195.1361417900771\n",
      "194.99098836444318\n",
      "194.84745078906417\n",
      "194.7053803037852\n",
      "194.5648146867752\n",
      "194.42580989655107\n",
      "194.28818462230265\n",
      "194.15187748800963\n",
      "194.01693042833358\n",
      "193.88340870849788\n",
      "193.75123294629157\n",
      "193.62063935864717\n",
      "193.49142045993358\n",
      "193.36343522835523\n",
      "193.23669418506324\n",
      "193.11124258767813\n",
      "192.9872141731903\n",
      "192.8643886782229\n",
      "192.74281351920217\n",
      "192.62250024825335\n",
      "192.50329965911806\n",
      "192.38521576114\n",
      "192.26835730392486\n",
      "192.1526820892468\n",
      "192.03813495114446\n",
      "191.92473446577787\n",
      "191.81222050078213\n",
      "191.70100119244307\n",
      "191.59065195173025\n",
      "191.48149953689426\n",
      "191.3732405146584\n",
      "191.26621226593852\n",
      "191.16014514956623\n",
      "191.05488332174718\n",
      "190.95086069218814\n",
      "190.84779819566756\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(100):\n",
    "    total_loss = 0\n",
    "    for context, target in trigrams:\n",
    "        context_idxs = torch.tensor([word_to_ix[w] for w in context], dtype=torch.long)\n",
    "        \n",
    "        model.zero_grad()\n",
    "        log_probs = model(context_idxs)\n",
    "        loss = loss_function(log_probs, torch.tensor([word_to_ix[target]], dtype=torch.long))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
